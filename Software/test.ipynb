{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import hdf5storage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.feature_selection import f_classif\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, GRU, LSTM, Dense\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "from pgmpy.estimators import PC\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Data Seperate All data in Protective and Non-Prtective Data\n",
    "\"\"\"\n",
    "\n",
    "# Assuming the 'Data' folder is in the current working directory\n",
    "data_folders = ['./Data']\n",
    "\n",
    "# Initialize lists to store the separated dataframes\n",
    "protective_dfs = []\n",
    "non_protective_dfs = []\n",
    "\n",
    "# Loop through each data folder\n",
    "for data_folder in data_folders:\n",
    "    # List all .mat files in the current data folder\n",
    "    mat_files = [f for f in os.listdir(data_folder) if f.endswith('.mat')]\n",
    "    # Load each mat file\n",
    "    for mat_file in mat_files:\n",
    "        # Construct the full path to the .mat file\n",
    "        mat_path = os.path.join(data_folder, mat_file)\n",
    "        # Load the .mat file\n",
    "        mat_data = loadmat(mat_path)\n",
    "        # Convert the data into a pandas dataframe\n",
    "        df = pd.DataFrame(mat_data['data'])\n",
    "        # Select only the first 70 columns and the last column (73rd) which contains the behavior label\n",
    "        df = df.iloc[:, list(range(66)) + [70] + [72]]\n",
    "        # Split the data based on the protective behavior label\n",
    "        # Assuming the last column in df is the protective behavior label\n",
    "        protective_behavior = df.iloc[:, -1]\n",
    "        protective_df = df[protective_behavior == 1]\n",
    "        non_protective_df = df[protective_behavior == 0]\n",
    "        # Append the resulting dataframes to their respective lists\n",
    "        protective_dfs.append(protective_df)\n",
    "        non_protective_dfs.append(non_protective_df)\n",
    "\n",
    "# Concatenate all protective and non-protective dataframes\n",
    "all_protective_data = pd.concat(protective_dfs, axis=0, ignore_index=True)\n",
    "all_non_protective_data = pd.concat(non_protective_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "exercise_labels = {\n",
    "    1: \"One-leg-stand\",\n",
    "    2: \"Reach-forward\",\n",
    "    3: \"Bend\",\n",
    "    4: \"Sit-to-stand\",\n",
    "    5: \"Stand-to-sit\",\n",
    "    6: \"Sitting still\",\n",
    "    7: \"Standing still\",\n",
    "    8: \"Walking\",\n",
    "    0: \"Others\"\n",
    "}\n",
    "def categorize_exercises(dataframe):\n",
    "    # Assuming the penultimate column in dataframe is the Exercise Type\n",
    "    exercise_type = dataframe.iloc[:, -2]\n",
    "    categorized_data = {}\n",
    "    for label, description in exercise_labels.items():\n",
    "        # Filter the dataframe by each exercise type\n",
    "        exercise_df = dataframe[exercise_type == label]\n",
    "        # Store the filtered dataframe in a dictionary\n",
    "        categorized_data[description] = exercise_df\n",
    "    return categorized_data\n",
    "\n",
    "\n",
    "# Categorize protective and non-protective dataframes\n",
    "categorized_protective = categorize_exercises(all_protective_data)\n",
    "categorized_non_protective = categorize_exercises(all_non_protective_data)\n",
    "# Now `all_protective_data` and `all_non_protective_data` hold the protective and non-protective data respectively\n",
    "# You can process these dataframes as needed for your analysis or save them to new .mat files\n",
    "# print(all_protective_data.shape)\n",
    "# print(all_non_protective_data.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14093, 68)\n",
      "(8652, 68)\n",
      "(6113, 68)\n",
      "(7735, 68)\n",
      "(10872, 68)\n",
      "(3968, 68)\n",
      "(2174, 68)\n",
      "(7554, 68)\n",
      "(16135, 68)\n"
     ]
    }
   ],
   "source": [
    "print(categorized_protective[\"One-leg-stand\"].shape)\n",
    "print(categorized_protective[\"Reach-forward\"].shape)\n",
    "print(categorized_protective[\"Bend\"].shape)\n",
    "print(categorized_protective[\"Sit-to-stand\"].shape)\n",
    "print(categorized_protective[\"Stand-to-sit\"].shape)\n",
    "print(categorized_protective[\"Sitting still\"].shape)\n",
    "print(categorized_protective[\"Standing still\"].shape)\n",
    "print(categorized_protective[\"Walking\"].shape)\n",
    "print(categorized_protective[\"Others\"].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46890, 68)\n",
      "(13703, 68)\n",
      "(7599, 68)\n",
      "(12084, 68)\n",
      "(10343, 68)\n",
      "(72003, 68)\n",
      "(87969, 68)\n",
      "(23263, 68)\n",
      "(163336, 68)\n"
     ]
    }
   ],
   "source": [
    "print(categorized_non_protective[\"One-leg-stand\"].shape)\n",
    "print(categorized_non_protective[\"Reach-forward\"].shape)\n",
    "print(categorized_non_protective[\"Bend\"].shape)\n",
    "print(categorized_non_protective[\"Sit-to-stand\"].shape)\n",
    "print(categorized_non_protective[\"Stand-to-sit\"].shape)\n",
    "print(categorized_non_protective[\"Sitting still\"].shape)\n",
    "print(categorized_non_protective[\"Standing still\"].shape)\n",
    "print(categorized_non_protective[\"Walking\"].shape)\n",
    "print(categorized_non_protective[\"Others\"].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
